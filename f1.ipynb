{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQvp3IWSYg6Q"
      },
      "source": [
        "# Modelling Formula 1 Outcomes for Fantasy EV Projections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_uy8JK3Yg6S"
      },
      "source": [
        "F1 Fantasy is well-suited to optimisation when compared to other fantasy sports. The problem space is relatively small - a team consists of only 5 assets, chosen from a pool of 30. You can also change half of your assets each race without a penalty, so planning more than 1 week ahead is almost always unneccesary. This makes for a much easier challenge than e.g. FPL optimisation, where we are choosing 15 assets from hundreds in a multi-period problem. Many drivers are either far too expenisve to be viable at their price point or sufficiently inexpensive to make them essential. Marginal decisions exist, but are less common than in other fantasy sports, which makes modelling it quite forgiving. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPIS99v7Y2Sd",
        "outputId": "3e8ebdb1-3ba2-4e6a-ad02-89cb66b867e8"
      },
      "outputs": [],
      "source": [
        "!pip install unidecode\n",
        "!pip install gurobipy\n",
        "!pip install pulp\n",
        "!pip install pandas\n",
        "!pip install unidecode\n",
        "!pip install seaborn\n",
        "!pip install scipy\n",
        "!pip install sklearn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u74WsxhPYg6S"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import product\n",
        "\n",
        "import unidecode\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy import optimize\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import gurobipy as gp\n",
        "from pulp import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14CEzE9DYnTA",
        "outputId": "07d7cc51-693c-4db1-992e-e286dc7b0027"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTJcJ2Y-Yg6U"
      },
      "source": [
        "To play Formula 1 Fantasy optimally, we split our process into two parts: predicting outcomes from which we can develop expected value projections, and using these projections to optimize our team. \n",
        "\n",
        "First, we need to model a probability distribution of outcomes (i.e. the likelihood of each outcome to occur to each driver). We are deriving estimates for the probability of these outcomes from odds."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AeEQ_4hnYg6U"
      },
      "source": [
        "## Converting Odds into Implied Probabilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Q_oNzpYg6U"
      },
      "source": [
        "The first step is to collect our odds. I use the shortest decimal odds available (i.e. highest decimal) across spread markets and traditional bookmakers.\n",
        "\n",
        "The relevant markets are winner, podium finish, top 6 finish, points finish, fastest lap, and to finish unclassified."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "zNDnJaRIYg6V",
        "outputId": "d1707a5f-3960-4746-a906-7ab8a671ac0d"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_csv('https://raw.githubusercontent.com/harryrgrove/F1_model/master/odds_input.csv', index_col=0)\n",
        "#df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/odds_input_2022.csv', index_col=0)\n",
        "df = pd.read_csv('odds_input_2022.csv', index_col=0)\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwwKl_XgYg6W"
      },
      "source": [
        "The basic implied probability from these projections can be obtained by finding their multiplicative inverse:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "6T8Eouc6Yg6X",
        "outputId": "9c8cdd28-fbba-4724-86b1-2a2df906681a"
      },
      "outputs": [],
      "source": [
        "odds_cols = ['winner', 'top3', 'top6', 'top10', 'flap', 'dnf']\n",
        "for col in odds_cols:\n",
        "    df[col] **= -1\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "jDIX9xzpYg6Y"
      },
      "source": [
        "Probabilities implied directly odds are never optimal to begin with because they are overrounded. There are many ways to adjust for this, as explained in this paper: http://article.sciencepublishinggroup.com/pdf/10.11648.j.ajss.20170506.12.pdf\n",
        "\n",
        "We will be using the \"power\" adjustment method favoured by the paper's authors. For example, if we want a column of probabilities to add to 1 (e.g. for race winner, since there can be only 1 winner), then we must raise each probability $p_i$ to the same exponent $k$, such that the sum of the probabilities raised to $k$ equals the desired total $T$, i.e. we want $k$ such that $\\sum_{i=1}^{20}p_i^k=T$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiVbj0lxYg6Y"
      },
      "outputs": [],
      "source": [
        "def adjust_odds(odds_series, target_sum, method='power'):\n",
        "    if method == 'power':\n",
        "        def f(x):\n",
        "            return sum([i**x for i in odds_series]) - target_sum\n",
        "        k = optimize.fsolve(f, 1) # optimise k such that the sum of p_i^k - T = 0\n",
        "        return odds_series ** k\n",
        "    elif method == 'linear':\n",
        "        return odds_series / sum(odds_series) * target_sum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4jdy9tAYg6Z"
      },
      "source": [
        "We want the winner column to add to 1, the top 3 column to add to 3, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "rD6cRfYVYg6Z",
        "outputId": "126041a7-c1c2-45fd-c563-1b7fe129325b"
      },
      "outputs": [],
      "source": [
        "for col, target in zip(odds_cols[:-1], [1, 3, 6, 10, 1]):\n",
        "    df[col] = adjust_odds(df[col], target)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHAMXB1_Yg6a"
      },
      "source": [
        "We also need to adjust our DNF odds, since currently they may show a driver's DNF probability and top 10 probability to add to more than 1, which is of course impossible.\n",
        "\n",
        "We can adjust these under the assumption that given a top driver finishes the race, they are 96% likely to finish in the top 10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "m1zRrNPOYg6a",
        "outputId": "115bbfc3-c285-4f62-b7df-1507f1dff99a"
      },
      "outputs": [],
      "source": [
        "df['dnf'] **= (np.log(0.96 - df['top10']) / np.log(df['dnf'])).max()\n",
        "df['winner'] = df[['winner', 'top3']].min(axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTN657kIYg6a"
      },
      "source": [
        "## Estimating Race Finishing Position Distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EX6YCVJNYg6b"
      },
      "source": [
        "After adjusting our odds, we can move on to looking at the probability distributions they imply. \n",
        "\n",
        "If we assume the probabilities are as uniform as the odds could possibly imply, this is what the implied distribution looks like for Pierre Gasly:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "TwaxA1X-Yg6b",
        "outputId": "b7a3e0ef-2a4e-426e-cbd8-608d770d4c42"
      },
      "outputs": [],
      "source": [
        "def get_probs(idx):\n",
        "    probs = [df.loc[idx, 'winner']]\n",
        "    probs += [(df.loc[idx, 'top3'] - df.loc[idx, 'winner'])/2] * 2\n",
        "    probs += [(df.loc[idx, 'top6'] - df.loc[idx, 'top3']) / 3] * 3\n",
        "    probs += [(df.loc[idx, 'top10'] - df.loc[idx, 'top6']) / 4] * 4\n",
        "    probs += [(1 - df.loc[idx, 'top10'] - df.loc[idx, 'dnf']) / 10] * 10\n",
        "    probs.append(df.loc[idx, 'dnf'])\n",
        "    return probs\n",
        "\n",
        "driver = 'Alonso'\n",
        "\n",
        "plt.bar(['P{}'.format(i) for i in range(1, 21)] + ['DNF'], get_probs(driver))\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('likelihood')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPxTmcXoYg6b"
      },
      "source": [
        "If we wanted, we could calculate expected value projections using these uniform distributions, and this would work fine. To improve them slightly (and also for the sake of fun), we want them to resemble a bell-curve. An easy way to do this is to minimize the squared difference between the implied probabilities of consecutive finishes, which can be done with quadratic optimisation.\n",
        "\n",
        "In other words, for each driver we need to solve the following optimisation problem, given $p_i$ is the probability a driver finishes in position $i$:\n",
        "\n",
        "$$\\text{Minimise} \\ \\sum_{i=1}^{19} (p_{i+1} - p_i)^2$$\n",
        "\n",
        "$$\\text{Subject to: } \\ p_1 = P(\\text{win}); \\ \\ \\sum_{i=1}^3 p_i = P(\\text{podium finish}); \\ \\ \\sum_{i=1}^6 p_i = P(\\text{top 6 finish}); \\\\ \\sum_{i=1}^{10} p_i = P(\\text{points finish}); \\ \\ \\sum_{i=11}^{20} p_i = 1 - P(\\text{points finish}) - P(\\text{dnf}).$$\n",
        "\n",
        "Let's first demonstrate on Gasly's probability distribution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        },
        "id": "mobKPFzDYg6c",
        "outputId": "bfbabb1b-4f93-4d27-d51c-87438058ae93"
      },
      "outputs": [],
      "source": [
        "quadratic_model = gp.Model('quadratic')\n",
        "quadratic_model.setParam('outputFlag', False)\n",
        "driver = 'Alonso'\n",
        "# Add the probability of finishing in each position as a model variable\n",
        "x = {i: quadratic_model.addVar(vtype=gp.GRB.CONTINUOUS, lb=0, ub=1, name=f'x_{i}') for i in range(1, 21)}\n",
        "# Set objective to minimize the differences between probabilities of consecutive positions\n",
        "obj = sum([(x[i] - x[i + 1])**2 for i in range(1, 20)])\n",
        "quadratic_model.setObjective(obj, gp.GRB.MINIMIZE)\n",
        "# Set model constraints\n",
        "quadratic_model.addConstr(x[1] == df.loc[driver, 'winner'])\n",
        "quadratic_model.addConstr(x[2] + x[3] == df.loc[driver, 'top3'] - df.loc[driver, 'winner'])\n",
        "quadratic_model.addConstr(x[4] + x[5] + x[6] == df.loc[driver, 'top6'] - df.loc[driver, 'top3'])\n",
        "quadratic_model.addConstr(x[7] + x[8] + x[9] + x[10] == df.loc[driver, 'top10'] - df.loc[driver, 'top6'])\n",
        "quadratic_model.addConstr(sum([x[i] for i in range(11, 21)]) == 1 - df.loc[driver, 'top10'] - df.loc[driver, 'dnf'])\n",
        "if df.loc[driver, 'top10'] >= 0.5:\n",
        "    quadratic_model.addConstr(x[20] == 0)\n",
        "# Optimize model parameters\n",
        "quadratic_model.optimize()\n",
        "vals = [v.x for v in quadratic_model.getVars()]\n",
        "plt.bar(['P{}'.format(i) for i in range(1, 21)] + ['DNF'], vals + [df.loc[driver, 'dnf']])\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('Probability')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXpCUanMYg6c"
      },
      "source": [
        "Much more satisfying! Now we can apply this method to all other drivers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UeJX2p0BYg6c",
        "outputId": "5ae58754-7ddb-43c4-da2f-a08b68f9a0f0"
      },
      "outputs": [],
      "source": [
        "pos_dict = {}\n",
        "\n",
        "for driver in df.index:\n",
        "    print(driver)\n",
        "    quadratic_model = gp.Model('quadratic')\n",
        "    quadratic_model.setParam('outputFlag', False)\n",
        "    x = {i: quadratic_model.addVar(vtype=gp.GRB.CONTINUOUS, lb=0, ub=1, name=f'x_{i}') for i in range(1, 21)}\n",
        "    obj = sum([(x[i] - x[i + 1])**2 for i in range(1, 20)])\n",
        "    quadratic_model.setObjective(obj, gp.GRB.MINIMIZE)\n",
        "    quadratic_model.addConstr(x[1] == df.loc[driver, 'winner'])\n",
        "    quadratic_model.addConstr(x[2] + x[3] == df.loc[driver, 'top3'] - df.loc[driver, 'winner'])\n",
        "    quadratic_model.addConstr(x[4] + x[5] + x[6] == df.loc[driver, 'top6'] - df.loc[driver, 'top3'])\n",
        "    quadratic_model.addConstr(x[7] + x[8] + x[9] + x[10] == df.loc[driver, 'top10'] - df.loc[driver, 'top6'])\n",
        "    quadratic_model.addConstr(sum([x[i] for i in range(11, 21)]) == 1 - df.loc[driver, 'top10'] - df.loc[driver, 'dnf'])\n",
        "    quadratic_model.optimize()\n",
        "    # print(quadratic_model.getVars())\n",
        "    pos_dict[driver] = {i + 1: v.x for i, v in enumerate(quadratic_model.getVars())}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hc3Ksdy-Yg6d"
      },
      "source": [
        "We can store this information in a DataFrame $\\texttt{pos_df}$, alongside other essential information such as mean projected position."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        },
        "id": "fb7ojPi9Yg6d",
        "outputId": "1a2c79d9-123e-4296-fa57-dd51dcf377d2"
      },
      "outputs": [],
      "source": [
        "pos_df = pd.DataFrame(pos_dict).T\n",
        "pos_df['dnf'] = df.dnf\n",
        "pos_df['team'] = df.team\n",
        "pos_df['mean_pos'] = sum([i / (1 - df['dnf']) * pos_df[i] for i in range(1, 21)])\n",
        "pos_df.head(10).T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuNDIG2sYg6d"
      },
      "source": [
        "We can also create another DataFrame $\\texttt{ev_df}$, which will store all the expected value of all sources of points, such as race position, dnf penalty, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "dJTV0HnHYg6e",
        "outputId": "7d6f54b1-4531-4345-9558-4a2e95358c19"
      },
      "outputs": [],
      "source": [
        "ev_df = pd.DataFrame(index=df.index)\n",
        "ev_df['race'] = 25 * pos_df[1] + 18 * pos_df[2] + 15 * pos_df[3] \\\n",
        "                 + 12 * pos_df[4] + 10 * pos_df[5] + 8 * pos_df[6] \\\n",
        "                 + 6 * pos_df[7] + 4 * pos_df[8] + 2 * pos_df[9] \\\n",
        "                 + pos_df[10] + (1 - pos_df['dnf']) * 1\n",
        "ev_df['flap'] = df['flap'] * 5\n",
        "ev_df['dnf'] = -15 * df['dnf']\n",
        "\n",
        "ev_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDYeObLaYg6e"
      },
      "source": [
        "## Modelling Sources of Points outside of Odds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow8he6RIYg6e"
      },
      "source": [
        "Next, we must estimate the value of other sources of points based on these race position distributions.\n",
        "\n",
        "There is little/no market data on these categories, so we can attempt to infer the distributions from past data analysis of players with similar race end expectations (i.e. running a linear regression to formulate expectations, then building probability distributions from this expectation matrix). First we need to collect data, which I've already stored in csv files for race data and result data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rAwtgL6Yg6e"
      },
      "outputs": [],
      "source": [
        "# race_df = pd.read_csv(\"https://raw.githubusercontent.com/harryrgrove/F1_model/master/races.csv\")\n",
        "race_df = pd.read_csv(\"f1db_csv/races.csv\")\n",
        "# result_df = pd.read_csv(\"https://raw.githubusercontent.com/harryrgrove/F1_model/master/results.csv\")\n",
        "result_df = pd.read_csv(\"f1db_csv/results.csv\")\n",
        "\n",
        "race_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pd6480UCYg6f"
      },
      "outputs": [],
      "source": [
        "# Gather IDs of all races\n",
        "race_dict = {}\n",
        "for year in range(2015, 2023):\n",
        "    races = race_df[race_df['year']==year]['raceId'].tolist()\n",
        "    race_dict[year] = races\n",
        "    \n",
        "# We are interested in how mean race position predicts mean grid position, mean fantasy points from quali, \n",
        "# % of Q2 finishes, % of Q3 finishes, and mean number of positions gained.\n",
        "values = {'grid': [], 'position': [], 'fantasy': [], 'top10': [], 'top15': [], 'mean_gain': []}\n",
        "\n",
        "# Iterate through the result data to collect these data points for each driver who raced more than 15\n",
        "# times in a season since 2015\n",
        "for year in race_dict:\n",
        "    season_df = result_df[result_df['raceId'].isin(race_dict[year])]\n",
        "    drivers = season_df['driverId'].unique()\n",
        "    for driver in drivers:\n",
        "        driver_df = season_df[season_df['driverId']==driver]\n",
        "        grid_pos_df = driver_df[['grid', 'position']][driver_df['position'].str.isnumeric() & (driver_df['grid'] != 0)]\n",
        "        grid_pos_df['grid'] = grid_pos_df['grid'].astype(float)\n",
        "        grid_pos_df['position'] = grid_pos_df['position'].astype(float)\n",
        "        \n",
        "        if len(grid_pos_df) > 15:\n",
        "            values['grid'].append(grid_pos_df['grid'].mean())\n",
        "            values['position'].append(grid_pos_df['position'].mean())\n",
        "            values['fantasy'].append(sum([sum(grid_pos_df['grid']==i) * \n",
        "                                          (11 - i) for i in range(1, 11)]) / len(grid_pos_df))\n",
        "            values['top10'].append(sum(grid_pos_df['grid'] <= 10) / len(grid_pos_df))\n",
        "            values['top15'].append(sum(grid_pos_df['grid'] <= 15) / len(grid_pos_df))\n",
        "\n",
        "            total = 0\n",
        "            for idx in grid_pos_df.index:\n",
        "                if grid_pos_df.loc[idx, 'grid'] - grid_pos_df.loc[idx, 'position'] > 0:\n",
        "                    total += min(10, (grid_pos_df.loc[idx, 'grid'] - grid_pos_df.loc[idx, 'position']) * 2)\n",
        "                elif grid_pos_df.loc[idx, 'grid'] - grid_pos_df.loc[idx, 'position'] < 0:\n",
        "                    if grid_pos_df.loc[idx, 'grid'] <= 10:\n",
        "                        total += max(-10, (grid_pos_df.loc[idx, 'grid'] - grid_pos_df.loc[idx, 'position']) * 2)\n",
        "                    else:\n",
        "                        total += max(-5, grid_pos_df.loc[idx, 'grid'] - grid_pos_df.loc[idx, 'position'])\n",
        "            values['mean_gain'].append(total / len(grid_pos_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nACgSdFpYg6f",
        "outputId": "48337321-76e6-4e7b-bfee-8fcc87f0661e"
      },
      "outputs": [],
      "source": [
        "result_df = pd.DataFrame(values)\n",
        "result_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tB4tim5uYg6f"
      },
      "source": [
        "First, let's model the points we expect from qualifying position from mean race finishing position. As seen below, this relationaship can be appropriately captured with a polynomial interpolation (degree 2)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "-l18hvllYg6f",
        "outputId": "a64c8f3d-b0e6-412a-d797-746ad3eef6bc"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='position', y='fantasy', data=result_df)\n",
        "weights = np.polyfit(result_df['position'], result_df['fantasy'], 2)\n",
        "model = np.poly1d(weights)\n",
        "x = np.linspace(1, 17)\n",
        "y = model(x)\n",
        "\n",
        "y_pred = model(result_df['position'])\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U244QOUkYg6g"
      },
      "source": [
        "From this relationship we can build a function to predict qualifying EV from mean race position."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STmYrgLuYg6g"
      },
      "outputs": [],
      "source": [
        "def qual_pts(pos):\n",
        "    weights = np.polyfit(result_df['position'], result_df['fantasy'], 2)\n",
        "    model = np.poly1d(weights)\n",
        "    return max(model(pos), 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hiyV8x-Yg6g"
      },
      "source": [
        "Next, let's do the same for modelling the probability of completing Q2 given a mean race position. A logistic relationship is clear in this case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "J14B03iCYg6g",
        "outputId": "18f0c879-6adb-4a03-c811-1a52ec1e5d05"
      },
      "outputs": [],
      "source": [
        "result_df = result_df.sort_values(by='position')\n",
        "sns.scatterplot(x=result_df['position'], y=result_df['top10'])\n",
        "\n",
        "x = result_df['position'].to_numpy()\n",
        "y = result_df['top10'].to_numpy()\n",
        "\n",
        "def f(x, a, b, c, d):\n",
        "    return a / (1. + np.exp(-c * (x - d))) + b\n",
        "\n",
        "popt, pcov = optimize.curve_fit(f, x, y, method=\"trf\")\n",
        "y_fit = f(x, *popt)\n",
        "plt.plot(x, y_fit, '-')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHVIP0W6Yg6h"
      },
      "source": [
        "From this relationship, we can model the number of points expected from Q2 appearance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWS26ht_Yg6h"
      },
      "outputs": [],
      "source": [
        "def q2_finish_pts(pos):\n",
        "    x = result_df['position'].to_numpy()\n",
        "    y = result_df['top10'].to_numpy()\n",
        "\n",
        "    def f(x, a, b, c, d):\n",
        "        return a / (1. + np.exp(-c * (x - d))) + b\n",
        "\n",
        "    popt, pcov = optimize.curve_fit(f, x, y, method=\"trf\")\n",
        "    return f(pos, *popt) * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4WCN5SOYg6h"
      },
      "source": [
        "Next, let's look at Q3 finishes. We can use the same logistic regression model as a reasonable estimate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "M5ALOZVtYg6h",
        "outputId": "3407ebbe-c07f-43f8-fc4a-1d0946c98d7c"
      },
      "outputs": [],
      "source": [
        "result_df = result_df.sort_values(by='position')\n",
        "sns.scatterplot(x=result_df['position'], y=result_df['top15'])\n",
        "\n",
        "x = result_df['position'].to_numpy()\n",
        "y = result_df['top15'].to_numpy()\n",
        "\n",
        "def f(x, a, b, c, d):\n",
        "    return a / (1. + np.exp(-c * (x - d))) + b\n",
        "\n",
        "popt, pcov = optimize.curve_fit(f, x, y, method=\"trf\")\n",
        "y_fit = f(x, *popt)\n",
        "plt.plot(x, y_fit, '-')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjbDfe6eYg6h"
      },
      "outputs": [],
      "source": [
        "def q3_finish_pts(pos):\n",
        "    x = result_df['position'].to_numpy()\n",
        "    y = result_df['top15'].to_numpy()\n",
        "\n",
        "    def f(x, a, b, c, d):\n",
        "        return a / (1. + np.exp(-c * (x - d))) + b\n",
        "\n",
        "    popt, pcov = optimize.curve_fit(f, x, y, method=\"trf\")\n",
        "    return max(f(pos, *popt) * 3, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag7gzQUhYg6i"
      },
      "source": [
        "Next, we want to look at modeling the relationship between expected race finish position and how many places one can be expected to gain in the race. A very loose but statistically significant correlation exists here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "Vv91UqeFYg6i",
        "outputId": "05eaaf7b-321d-4bd0-c311-6a17eca3ab23"
      },
      "outputs": [],
      "source": [
        "sns.lmplot(x='position', y='mean_gain', data=result_df)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWlGP8g1Yg6i"
      },
      "outputs": [],
      "source": [
        "def gain_pts(pos):  \n",
        "    x, y = result_df['position'].values.reshape(-1, 1), result_df['mean_gain'].values.reshape(-1,1)\n",
        "    reg = LinearRegression().fit(x, y)\n",
        "    return reg.predict(np.array(pos).reshape(-1, 1))[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Or18ZZEnYg6i"
      },
      "source": [
        "We can add the expected points from these new sources to $\\texttt{ev_df}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "3uLD95xtYg6i",
        "outputId": "2aad8878-7540-43e4-c652-08d35bb3162e"
      },
      "outputs": [],
      "source": [
        "ev_df['qual'] = [qual_pts(i) for i in pos_df['mean_pos']]\n",
        "ev_df['gain'] = [gain_pts(i) for i in pos_df['mean_pos']]\n",
        "ev_df['q'] = [q2_finish_pts(i) + q3_finish_pts(i) for i in pos_df['mean_pos']]\n",
        "ev_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g1UMV8WxYg6i"
      },
      "source": [
        "The next source of points to model is when drivers beat their teammates. Since we now have more data from this season to work from, we can use this to better effect than historical data. First we need to scrape this season's data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baAaU5yqYg6j",
        "outputId": "fa56972c-d16e-4cd7-d58a-f8501df5cae7"
      },
      "outputs": [],
      "source": [
        "hrefs = [\n",
        "    \"1124/bahrain\",\n",
        "    # \"1125/saudi-arabia\"\n",
        "]\n",
        "\n",
        "qualifying_dfs, race_dfs, grid_dfs = [], [], []\n",
        "season_length = 1 # Update after each race\n",
        "\n",
        "# Collect qualifying, race and grid orders for this season's GPs\n",
        "for href in hrefs[:season_length]:\n",
        "    qualifying_url = f'https://www.formula1.com/en/results.html/2022/races/{href}/qualifying.html'\n",
        "    qualifying_df = pd.read_html(qualifying_url)[0]\n",
        "    # print(qualifying_df)\n",
        "    qualifying_df['Driver'] = [unidecode.unidecode(name.split('  ')[1]) \n",
        "                               for name in qualifying_df['Driver']]\n",
        "    qualifying_df['Driver'] = ['Zhou' if driver=='Guanyu' else driver for driver in qualifying_df['Driver']]\n",
        "    qualifying_df['Driver'] = ['Vettel' if driver=='Hulkenberg' else driver for driver in qualifying_df['Driver']]\n",
        "    qualifying_dfs.append(qualifying_df.set_index('Driver')[['Pos', 'Car', 'Q2', 'Q3']])\n",
        "    # print(qualifying_df)\n",
        "    \n",
        "    race_url = f'https://www.formula1.com/en/results.html/2022/races/{href}.html'\n",
        "    race_df = pd.read_html(race_url)[0]\n",
        "    race_df['Driver'] = [unidecode.unidecode(name.split('  ')[1]) for name in race_df['Driver']]\n",
        "    race_df['Driver'] = ['Zhou' if driver=='Guanyu' else driver for driver in race_df['Driver']]\n",
        "    race_df['Driver'] = ['Vettel' if driver=='Hulkenberg' else driver for driver in race_df['Driver']]\n",
        "    race_dfs.append(race_df.set_index('Driver')[['Pos', 'Car', 'Time/Retired']])\n",
        "    \n",
        "    grid_url = f'https://www.formula1.com/en/results.html/2022/races/{href}/starting-grid.html'\n",
        "    grid_df = pd.read_html(grid_url)[0]\n",
        "    grid_df['Driver'] = [unidecode.unidecode(name.split('  ')[1]) for name in grid_df['Driver']]\n",
        "    # print(grid_df)\n",
        "    grid_df['Driver'] = ['Zhou' if driver=='Guanyu' else driver for driver in grid_df['Driver']]\n",
        "    grid_df['Driver'] = ['Vettel' if driver=='Hulkenberg' else driver for driver in grid_df['Driver']]\n",
        "    print(grid_df['Driver'])\n",
        "    grid_dfs.append(grid_df.set_index('Driver')[['Pos', 'Car']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lSTz7ciYg6j"
      },
      "source": [
        "Next, we can use this data to see how often each driver beats their teammate, as well as their distribution of position gains and whether they tend to complete Q2 and Q3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "3TADbIxHYg6j",
        "outputId": "c8cc759b-f5ea-41f8-de88-b6bcaf09343f"
      },
      "outputs": [],
      "source": [
        "drivers = race_dfs[0].index\n",
        "\n",
        "event_df = pd.DataFrame(index=drivers)\n",
        "event_df['team'] = race_dfs[0].Car\n",
        "event_df['beat_teammate_race'] = np.empty((20, 0)).tolist()\n",
        "event_df['beat_teammate_qualifying'] = np.empty((20, 0)).tolist()\n",
        "\n",
        "event_df['position_gain'] = np.empty((20, 0)).tolist()\n",
        "event_df['q2_finish'] = np.empty((20, 0)).tolist()\n",
        "event_df['q3_finish'] = np.empty((20, 0)).tolist()\n",
        "\n",
        "\n",
        "\n",
        "for i, (race_df, qualifying_df, grid_df) in enumerate(zip(race_dfs, qualifying_dfs, grid_dfs)):\n",
        "    for team in race_df['Car'].unique():\n",
        "        # Collect teammate race data\n",
        "        team_df = race_df.loc[race_df['Car']==team]\n",
        "        try:\n",
        "            event_df.loc[team_df.index[0], 'beat_teammate_race'].append(1)\n",
        "            event_df.loc[team_df.index[1], 'beat_teammate_race'].append(0)\n",
        "        except IndexError:\n",
        "            continue\n",
        "        except KeyError:\n",
        "            continue\n",
        "\n",
        "        # Collect teammate qualifying data\n",
        "        team_df = qualifying_df.loc[qualifying_df['Car']==team]\n",
        "        try:\n",
        "            event_df.loc[team_df.index[1], 'beat_teammate_qualifying'].append(0)\n",
        "            event_df.loc[team_df.index[0], 'beat_teammate_qualifying'].append(1)\n",
        "        except IndexError:\n",
        "            continue\n",
        "\n",
        "    for driver in drivers:\n",
        "        # Collect position gain data\n",
        "        if race_df.loc[driver, 'Pos'] == 'NC':\n",
        "            gain = 0\n",
        "        elif race_df.loc[driver, 'Time/Retired'] in ['DNF', 'DNS']:\n",
        "            gain = 0\n",
        "        else:\n",
        "            try:\n",
        "                gain = int(grid_df.loc[driver, 'Pos']) - int(race_df.loc[driver, 'Pos'])\n",
        "            except KeyError:\n",
        "                gain = 20 - int(race_df.loc[driver, 'Pos'])\n",
        "            except ValueError:\n",
        "                gain = 0\n",
        "        event_df.loc[driver, 'position_gain'].append(gain)\n",
        "        \n",
        "        # Collect Q2 qualification data\n",
        "        try:\n",
        "            if pd.isnull(qualifying_df.loc[driver, 'Q2']):\n",
        "                event_df.loc[driver, 'q2_finish'].append(0)\n",
        "            else:\n",
        "                event_df.loc[driver, 'q2_finish'].append(1)\n",
        "        except KeyError:\n",
        "            event_df.loc[driver, 'q2_finish'].append(0)\n",
        "        \n",
        "        # Collect Q3 qualification data\n",
        "        try:\n",
        "            if pd.isnull(qualifying_df.loc[driver, 'Q3']):\n",
        "                event_df.loc[driver, 'q3_finish'].append(0)\n",
        "            else:\n",
        "                event_df.loc[driver, 'q3_finish'].append(1)\n",
        "        except KeyError:\n",
        "            event_df.loc[driver, 'q3_finish'].append(0)\n",
        "\n",
        "# We must normalise each probability towards mean to account for sample noise\n",
        "event_df['P(beat_teammate_race)'] = [np.mean(l) for l in event_df['beat_teammate_race']]\n",
        "event_df['P(beat_teammate_race)'] = (5 * event_df['P(beat_teammate_race)'] + 0.5) / 6\n",
        "event_df['P(beat_teammate_qualifying)'] = [np.mean(l) for l in event_df['beat_teammate_qualifying']]\n",
        "event_df['P(beat_teammate_qualifying)'] = (5 * event_df['P(beat_teammate_qualifying)'] + 0.5) / 6\n",
        "event_df = pd.DataFrame(event_df[['team', 'P(beat_teammate_race)', 'P(beat_teammate_qualifying)']])\n",
        "event_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol3S9nncYg6k"
      },
      "source": [
        "Finally, we must adjust the beating teammate probabilities to take into account the events that either (or both) drivers in each team are not classified in the race:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "XGll447PYg6k",
        "outputId": "faae7af9-1ddb-4844-ea92-fdfb1c37652d"
      },
      "outputs": [],
      "source": [
        "for team in event_df.team.unique():\n",
        "    drivers = event_df[event_df['team']==team].index.tolist()\n",
        "    print(drivers)\n",
        "    p_no_dnf = (1 - df.loc[drivers[0], 'dnf']) * (1 - df.loc[drivers[1], 'dnf'])\n",
        "    \n",
        "    adjusted = adjust_odds(np.array(event_df.loc[drivers, 'P(beat_teammate_race)']), p_no_dnf, method='linear')\n",
        "    event_df.loc[drivers, 'P(beat_teammate_race)'] = adjusted\n",
        "    \n",
        "    event_df.loc[drivers[0], 'P(beat_teammate_race)'] += (1 - df.loc[drivers[0], 'dnf']) * df.loc[drivers[1], 'dnf']\n",
        "    event_df.loc[drivers[1], 'P(beat_teammate_race)'] += (1 - df.loc[drivers[1], 'dnf']) * df.loc[drivers[0], 'dnf']\n",
        "    \n",
        "event_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l0-Gyc4Yg6k"
      },
      "outputs": [],
      "source": [
        "for driver in df.index:\n",
        "    ev_df.loc[driver, 'beat_teammate'] = event_df.loc[driver, 'P(beat_teammate_race)'] * 3 \\\n",
        "                                        + event_df.loc[driver, 'P(beat_teammate_qualifying)'] * 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyxX93vtYg6k"
      },
      "source": [
        "The last source of Fantasy F1 points we need to model is streaks - drivers get 5 points for a qualifying streak and 10 points for a race streak."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_4rEURrYg6k"
      },
      "outputs": [],
      "source": [
        "q_streak_drivers = ['Hamilton', 'Verstappen', 'Russell', 'Leclerc', 'Perez', 'Sainz', 'Gasly', 'Alonso', 'Bottas', 'Magnussen']\n",
        "race_streak_drivers = ['Hamilton', 'Russell', 'Leclerc',\n",
        "                        'Sainz', 'Ocon', 'Tsunoda', 'Zhou', 'Alonso', 'Bottas', 'Magnussen']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "BpVQm-WqYg6l",
        "outputId": "d877a230-1c27-432e-dfd4-b5475fa23dc2"
      },
      "outputs": [],
      "source": [
        "for driver in pos_df.index:\n",
        "    if driver in q_streak_drivers:\n",
        "        streak_prob = q3_finish_pts(pos_df.loc[driver, 'mean_pos']) / 3\n",
        "        ev_df.loc[driver, 'q_streak'] = streak_prob * 5\n",
        "    else:\n",
        "        ev_df.loc[driver, 'q_streak'] = 0\n",
        "\n",
        "for driver in pos_df.index:\n",
        "    if driver in race_streak_drivers:\n",
        "        streak_prob = sum([pos_df.loc[driver, i] for i in range(1,11)])\n",
        "        ev_df.loc[driver, 'race_streak'] = streak_prob * 10\n",
        "    else:\n",
        "        ev_df.loc[driver, 'race_streak'] = 0\n",
        "        \n",
        "ev_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipxp-lVTYg6l"
      },
      "source": [
        "And those are all the point sources for drivers! Let's compile this into a new DataFrame to review:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "nuwk3FbbYg6l",
        "outputId": "4053cb3c-d3b0-4ec3-e748-f3a8e017f6e8"
      },
      "outputs": [],
      "source": [
        "driver_df = pd.DataFrame(ev_df.T.sum(), columns=['EV'])\n",
        "driver_df.sort_values(by='EV', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQ8LjmFVYg6l"
      },
      "source": [
        "Next, let's add up the current points projections for constructors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "oMKWmhC4Yg6l",
        "outputId": "fcb7eccf-8248-4f6e-d632-19d0e1a2fec6"
      },
      "outputs": [],
      "source": [
        "team_df = pd.DataFrame(index=pos_df['team'].unique().tolist())\n",
        "\n",
        "for team in pos_df['team'].unique():\n",
        "    t_df = ev_df[pos_df['team']==team]\n",
        "    team_df.loc[team, 'EV'] = t_df['race'].sum() + t_df['qual'].sum() + t_df['q'].sum() + t_df['gain'].sum() \n",
        "team_df.sort_values(by='EV', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZjWC2qpYg6m"
      },
      "source": [
        "Constructors also get 5 points if both of their drivers get streaks in qualifying and 10 in race. We can work out the probability of this happening with the values from $\\texttt{pos_df}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AiXn-VrYg6m"
      },
      "outputs": [],
      "source": [
        "q_streak_teams = ['Mercedes', 'Red Bull', 'Ferrari']\n",
        "race_streak_teams = ['Mercedes', 'Ferrari', 'Alfa Romeo']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "vR8C3rfzYg6m",
        "outputId": "4668e1c2-6109-4614-ae71-d148d9fda2ba"
      },
      "outputs": [],
      "source": [
        "for team in q_streak_teams:\n",
        "    drivers = pos_df[pos_df['team']==team].index.tolist()\n",
        "    streak_prob = q3_finish_pts(pos_df.loc[drivers[0], 'mean_pos']) / 3 * q3_finish_pts(pos_df.loc[drivers[1], 'mean_pos']) / 3\n",
        "    team_df.loc[team, 'EV'] += streak_prob * 5\n",
        "\n",
        "for team in race_streak_teams:\n",
        "    drivers = pos_df[pos_df['team']==team].index.tolist()\n",
        "    streak_prob = sum([pos_df.loc[drivers[0], i] for i in range(1,11)]) * sum([pos_df.loc[drivers[1], i] for i in range(1,11)])\n",
        "    team_df.loc[team, 'EV'] += streak_prob * 10\n",
        "\n",
        "team_df.sort_values(by='EV', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "170AHhssYg6m"
      },
      "source": [
        "## Optimising EV Projections"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qc0VCpqyYg6m"
      },
      "source": [
        "Now we move onto the last part of the model - using these EV projections to optimise teams.\n",
        "\n",
        "To do this, we need to get the prices of each driver and constructor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hubCUZEcYg6m"
      },
      "outputs": [],
      "source": [
        "driver_prices = {\n",
        "    'Hamilton': 30.8,\n",
        "    'Verstappen': 30.5,\n",
        "    'Perez': 17.6,\n",
        "    'Bottas': 9.4,\n",
        "    'Norris': 15.6,\n",
        "    'Leclerc': 18.5,\n",
        "    'Gasly': 13.4,\n",
        "    'Ricciardo': 14.0,\n",
        "    'Sainz': 17.2,\n",
        "    'Tsunoda': 8.4,\n",
        "    'Alonso': 12.5,\n",
        "    'Stroll': 9.2,\n",
        "    'Vettel': 11.5,\n",
        "    'Ocon': 12.2,\n",
        "    'Russell': 23.9,\n",
        "    'Zhou': 8.1,\n",
        "    'Albon': 7.4,\n",
        "    'Latifi': 6.9,\n",
        "    'Schumacher': 6.5,\n",
        "    'Magnussen': 5.9,\n",
        "}\n",
        "\n",
        "team_prices = {\n",
        "    'Mercedes': 34.3,\n",
        "    'Red Bull': 32.4,\n",
        "    'McLaren': 17.9,\n",
        "    'Ferrari': 25.6,\n",
        "    'Alphatauri': 10.4,\n",
        "    'Aston Martin': 11.3,\n",
        "    'Alpine': 13.9,\n",
        "    'Alfa Romeo': 8.3,\n",
        "    'Williams': 6.8,\n",
        "    'Haas': 6.2\n",
        "}\n",
        "\n",
        "for i in driver_prices:\n",
        "    driver_df.loc[i, 'price'] = driver_prices[i]\n",
        "\n",
        "for i in team_prices:\n",
        "    team_df.loc[i, 'price'] = team_prices[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 990
        },
        "id": "iPtDnB0-Yg6m",
        "outputId": "e6508fad-1ee8-4e1f-dbef-1f10baa74c19"
      },
      "outputs": [],
      "source": [
        "pd.concat([team_df.sort_values(by='EV', ascending=False), driver_df.sort_values(by='EV', ascending=False)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "onwS4XKPYg6n",
        "outputId": "36b3fa3d-ffe0-4c77-ed82-d0a5cc94cfd6"
      },
      "outputs": [],
      "source": [
        "driver_df.sort_values(by='EV', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-tWJq9lYg6n"
      },
      "source": [
        "At last we are ready to construct a linear optimisation model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SQeowE21Yg6n"
      },
      "outputs": [],
      "source": [
        "def solve_team(budget, owned_drivers, owned_team, force_include, force_exclude, transfers=3):\n",
        "    # Turn owned_drivers and owned_team into an array for linear programming\n",
        "    owned_drivers = {d: 0 + int(d in owned_drivers) for d in driver_df.index}\n",
        "    owned_team = {c: 0 + int(c == owned_team) for c in team_df.index}\n",
        "\n",
        "    # Initialise optimisation problem and set up decision variables\n",
        "    prob = LpProblem(\"F1_model\", LpMaximize)\n",
        "    drivers = LpVariable.dicts('drivers', driver_df.index, cat='Binary')\n",
        "    teams = LpVariable.dicts('teams', team_df.index, cat='Binary')\n",
        "    turbo = LpVariable.dicts('turbo', driver_df.index, cat='Binary')\n",
        "\n",
        "    # Set objective function\n",
        "    prob += lpSum([drivers[d] * driver_df.loc[d, 'EV'] for d in drivers]) \\\n",
        "            + lpSum([teams[t] * team_df.loc[t, 'EV'] for t in teams]) \\\n",
        "            + lpSum([turbo[d] * driver_df.loc[d, 'EV'] for d in drivers])\n",
        "\n",
        "    # Constrain number of drivers to 5, and number of teams and turbo drivers to 1\n",
        "    prob += lpSum(drivers) == 5\n",
        "    prob += lpSum(teams) == 1\n",
        "    prob += lpSum(turbo) == 1\n",
        "    \n",
        "    # Total price of assets must be less than or equal to total budget\n",
        "    prob += lpSum([drivers[d] * driver_df.loc[d, 'price'] for d in drivers]) + \\\n",
        "            lpSum([teams[t] * team_df.loc[t, 'price'] for t in teams]) <= budget\n",
        "\n",
        "    # Turbo driver must cost at most 19.9\n",
        "    prob += lpSum([turbo[d] * driver_df.loc[d, 'price'] for d in drivers]) <= 19.9\n",
        "    for d in drivers:\n",
        "        prob += turbo[d] <= drivers[d]\n",
        "    \n",
        "    # The total number of assets kept the same must be at least 6 minus the number of available transfers\n",
        "    prob += lpSum([owned_drivers[d] * drivers[d] for d in drivers]) \\\n",
        "                + lpSum([owned_team[t] * teams[t] for t in teams]) >= 6 - transfers\n",
        "\n",
        "    # Force the inclusion and exclusion of given drivers and teams\n",
        "    for d in force_include['driver']:\n",
        "        prob += drivers[d] == 1\n",
        "    for t in force_include['team']:\n",
        "        prob += teams[t] == 1\n",
        "    for d in force_exclude['driver']:\n",
        "        prob += drivers[d] == 0\n",
        "    for t in force_exclude['team']:\n",
        "        prob += team[t] == 0\n",
        "    \n",
        "    # We can expect Schumacher to outscore Latifi & Russell\n",
        "    for d in ['Latifi']:\n",
        "        prob += drivers[d] <= drivers['Schumacher']\n",
        "\n",
        "    # Solve problem and return optimal decision variables and objective value\n",
        "    status = prob.solve()\n",
        "    return {\n",
        "        'drivers': sorted([d for d in drivers if drivers[d].varValue == 1], key=lambda x: -driver_prices[x]),\n",
        "        'team': [t for t in teams if teams[t].varValue == 1][0],\n",
        "        'turbo driver': [d for d in drivers if turbo[d].varValue == 1][0],\n",
        "        'EV': value(prob.objective)\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hgvYkc7Yg6n"
      },
      "source": [
        "Let's solve the problem for my team this week!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ML_igThDYg6n",
        "outputId": "6af3c710-7c91-4045-d668-ee1e0cc783af"
      },
      "outputs": [],
      "source": [
        "print(\n",
        "    solve_team(\n",
        "        budget=100,\n",
        "        owned_drivers=['Leclerc', 'Sainz', 'Perez', 'Bottas', 'Magnussen'],\n",
        "        owned_team='Red Bull',\n",
        "        force_include={'driver': [], 'team': []},\n",
        "        force_exclude={'driver': [], 'team': []},\n",
        "        transfers=3,\n",
        "    )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6IAOGJ5Yg6o"
      },
      "source": [
        "Over a range of different prices, here are the optimal solutions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "8R3rC4JAYg6o",
        "outputId": "4aa3b3dd-bab3-4e58-c94a-ff6f463600c8"
      },
      "outputs": [],
      "source": [
        "optimal_teams = {}\n",
        "\n",
        "min_budget, max_budget = 99, 105\n",
        "last_team = {}\n",
        "b = min_budget\n",
        "while b <= max_budget:\n",
        "    b = round(b, 1)\n",
        "    team = solve_team(\n",
        "                budget=b,\n",
        "                owned_drivers=[],\n",
        "                owned_team='',\n",
        "                force_include={'driver': ['Perez'], 'team': ['Red Bull']},\n",
        "                force_exclude={'driver': [], 'team': []},\n",
        "                transfers=12\n",
        "                )\n",
        "    if team != last_team:\n",
        "        optimal_teams[b] = team\n",
        "    last_team = team\n",
        "    b += 0.1\n",
        "\n",
        "out_df = pd.DataFrame(optimal_teams).T\n",
        "for i in range(5):\n",
        "    out_df[f'driver {i+1}'] = [d[i] for d in out_df['drivers']]\n",
        "out_df.index = [f'{out_df.index[i-1]}-{round(out_df.index[i] - 0.1, 1)}' \n",
        "                for i in range(1, len(out_df))] + [f'{out_df.index[-1]}-{max_budget}']\n",
        "out_df.index.name = 'budget range'\n",
        "out_df.drop('drivers', axis=1)[['driver 1', 'driver 2', 'driver 3', 'driver 4', 'driver 5', \n",
        "                                'turbo driver', 'team', 'EV']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SpvRdnGYg6o"
      },
      "source": [
        "The accuracy of the model is difficult to test. Fantasy F1 is extremely high-variance, and there is no data available to back-test. There is also no hindsight metric available to reduce noise, such as xG can be used for football. Initial results are positive though; so far this season I am in the top 2.5% of players, despite lacking anything beyond a very novice knowledge of F1."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "f1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
